#!/usr/bin/env python3
import os
import sys
import re

ALIAS_FILE = 'building/Aliases'
ALIAS_INC = 'src/charset/aliases.inc'

if len(sys.argv) > 1:
    ALIAS_INC = sys.argv[1]

UNICODE_CHARSETS = [
    re.compile(r'^ISO-10646-UCS-[24]$'),
    re.compile(r'^UTF-16'),
    re.compile(r'^UTF-8$'),
    re.compile(r'^UTF-32')
]

def main():
    if not os.path.exists(ALIAS_FILE):
        sys.exit(f"Unable to open {ALIAS_FILE}")

    charsets = {}
    
    with open(ALIAS_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            parts = line.split()
            if not parts:
                continue
                
            canon = parts[0]
            mibenum = parts[1]
            aliases = parts[2:]
            charsets[canon] = (mibenum, aliases)

    unicodeexp_list = []
    
    aliases_map = {}
    canonnr = 0
    
    sorted_canons = sorted(charsets.keys())
    
    out_str = ""
    out_str += "/*\n"
    cmd = 'python ' + ' '.join(sys.argv)
    out_str += " * This file is auto-generated.\n"
    out_str += " * DO NOT EDIT THIS FILE DIRECTLY.\n"
    out_str += f" * Command: {cmd}\n"
    out_str += " */\n\n"
    out_str += "/*\n"
    out_str += " * This file is part of LibParserUtils.\n"
    out_str += " * Licensed under the MIT License,\n"
    out_str += " *                http://www.opensource.org/licenses/mit-license.php\n"
    out_str += " * Copyright 2010 The NetSurf Project.\n"
    out_str += " *\n"
    out_str += " * Note: This file is automatically generated by make-aliases.py\n"
    out_str += " *\n"
    out_str += " * Do not edit file file, changes will be overwritten during build.\n"
    out_str += " */\n\n"
    
    out_str += "static parserutils_charset_aliases_canon canonical_charset_names[] = {\n"
    
    for canon in sorted_canons:
        mibenum, elements = charsets[canon]
        # Ordering must match struct in src/charset/aliases.h
        out_str += f'\t{{ {mibenum}, {len(canon)}, "{canon}" }},\n'
        
        isunicode = False
        for unirexp in UNICODE_CHARSETS:
            if unirexp.search(canon):
                isunicode = True
                break
        
        if isunicode:
            unicodeexp_list.append(f"((x) == {mibenum})")
            
        # Normalize canon
        norm_canon = re.sub(r'[^a-z0-9]', '', canon.lower())
        aliases_map[norm_canon] = canonnr
        
        for alias in elements:
            norm_alias = re.sub(r'[^a-z0-9]', '', alias.lower())
            aliases_map[norm_alias] = canonnr
            
        canonnr += 1

    out_str += "};\n\n"
    out_str += f"static const uint16_t charset_aliases_canon_count = {canonnr};\n\n"
    
    out_str += "typedef struct {\n"
    out_str += "\tuint16_t name_len;\n"
    out_str += "\tconst char *name;\n"
    out_str += "\tparserutils_charset_aliases_canon *canon;\n"
    out_str += "} parserutils_charset_aliases_alias;\n\n"
    
    out_str += "static parserutils_charset_aliases_alias charset_aliases[] = {\n"
    
    aliascount = 0
    sorted_aliases = sorted(aliases_map.keys())
    
    for alias in sorted_aliases:
        cnr = aliases_map[alias]
        out_str += f'\t{{ {len(alias)}, "{alias}", &canonical_charset_names[{cnr}] }},\n'
        aliascount += 1
        
    out_str += "};\n\n"
    
    if unicodeexp_list:
        unicodeexp = " || ".join(unicodeexp_list)
    else:
        unicodeexp = ""
        
    out_str += f"static const uint16_t charset_aliases_count = {aliascount};\n\n"
    out_str += f"#define MIBENUM_IS_UNICODE(x) ({unicodeexp})\n"
    
    # Check existing
    if os.path.exists(ALIAS_INC):
        with open(ALIAS_INC, 'r', encoding='utf-8') as f:
            current_content = f.read()
        # Allow update if content differs
        if current_content == out_str:
            return

    with open(ALIAS_INC, 'w', encoding='utf-8') as f:
        f.write(out_str)

if __name__ == "__main__":
    main()
